{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CBET_CNN1d.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnXA82keW2tz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a50791a9-dd72-4dc0-8e47-56fdcf96991b"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "#gpuの確認\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXoP3THJXB1B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "89a12a0a-7cb4-433f-ff98-a56204372b2d"
      },
      "source": [
        "#学習済みの分散表現をロードする\n",
        "from torchtext.vocab import Vectors\n",
        "\n",
        "english_fasttext_vectors = Vectors(name='drive/My Drive/wiki-news-300d-1M.vec')\n",
        "\n",
        "print(english_fasttext_vectors.dim)\n",
        "print(len(english_fasttext_vectors.itos))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/999994 [00:00<?, ?it/s]Skipping token b'999994' with 1-dimensional vector [b'300']; likely a header\n",
            "100%|█████████▉| 999430/999994 [02:04<00:00, 7908.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "300\n",
            "999994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iApeSOnfXFyO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "abf5e581-e6b1-42fc-d11c-2a127b63e663"
      },
      "source": [
        "import string\n",
        "import re\n",
        "\n",
        "# 以下の記号はスペースに置き換えます（カンマ、ピリオドを除く）。\n",
        "# punctuationとは日本語で句点という意味です\n",
        "print(\"区切り文字：\", string.punctuation)\n",
        "# !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
        "\n",
        "# 前処理\n",
        "\n",
        "\n",
        "def preprocessing_text(text):\n",
        "    # 改行コードを消去\n",
        "    text = re.sub('<br />', '', text)\n",
        "\n",
        "    # カンマ、ピリオド以外の記号をスペースに置換\n",
        "    for p in string.punctuation:\n",
        "        if (p == \".\") or (p == \",\"):\n",
        "            continue\n",
        "        else:\n",
        "            text = text.replace(p, \" \")\n",
        "\n",
        "    # ピリオドなどの前後にはスペースを入れておく\n",
        "    text = text.replace(\".\", \" . \")\n",
        "    text = text.replace(\",\", \" , \")\n",
        "    return text\n",
        "\n",
        "# 分かち書き（今回はデータが英語で、簡易的にスペースで区切る）\n",
        "\n",
        "\n",
        "def tokenizer_punctuation(text):\n",
        "    return text.strip().split()\n",
        "\n",
        "\n",
        "# 前処理と分かち書きをまとめた関数を定義\n",
        "def tokenizer_with_preprocessing(text):\n",
        "    text = preprocessing_text(text)\n",
        "    ret = tokenizer_punctuation(text)\n",
        "    return ret\n",
        "\n",
        "\n",
        "# 動作を確認します\n",
        "print(tokenizer_with_preprocessing('I like cats+'))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "区切り文字： !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "['I', 'like', 'cats']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qlvXQfbXHyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchtext\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "#テキストに処理を行うFieldを定義\n",
        "#fix_lengthはtokenの数\n",
        "TEXT = torchtext.data.Field(sequential=True, use_vocab=True, tokenize=tokenizer_with_preprocessing,\n",
        "                            lower=True, include_lengths=True, batch_first=True, fix_length=37)\n",
        "\n",
        "LABEL = torchtext.data.Field(sequential=False, use_vocab=False)\n",
        "\n",
        "#pandasでcsvを保存するときに、labelをintでキャストしておかないとエラーでるから注意\n",
        "train_ds, val_ds, test_ds = torchtext.data.TabularDataset.splits(\n",
        "    path='drive/My Drive/dataset/CBET/ekman', train='train.csv', validation='val.csv', \n",
        "    test='test.csv', format='csv', fields=[('Text', TEXT), ('Label', LABEL)])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7_COqTpXJ6Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cd76e052-3dec-428a-c5ae-0ba8f4948474"
      },
      "source": [
        "#ボキャブラリを作成する\n",
        "TEXT.build_vocab(train_ds, vectors=english_fasttext_vectors)\n",
        "\n",
        "print(len(TEXT.vocab.stoi))\n",
        "\n",
        "batch_size = 64\n",
        "d_model = 300\n",
        "num_filters = [100, 100, 100]\n",
        "filter_sizes = [3, 4, 5]\n",
        "num_unit = 100\n",
        "output_dim = 5\n",
        "dropout_rate = 0.5"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "51709\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeGUx8adXL0-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7a3a1322-7505-47a4-e5b7-ab32c0c0ba98"
      },
      "source": [
        "#データローダを作成\n",
        "train_dl = torchtext.data.Iterator(train_ds, batch_size=batch_size, train=True)\n",
        "val_dl = torchtext.data.Iterator(val_ds, batch_size=batch_size, train=False, sort=False)\n",
        "test_dl = torchtext.data.Iterator(test_ds, batch_size=batch_size, train=False, sort=False)\n",
        "\n",
        "#テスト\n",
        "batch = next(iter(val_dl))\n",
        "print(len(batch.Text[0][0]))\n",
        "print(batch.Label)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37\n",
            "tensor([4, 0, 2, 0, 2, 4, 4, 3, 1, 4, 2, 2, 1, 2, 2, 2, 1, 2, 3, 3, 0, 3, 4, 1,\n",
            "        1, 3, 0, 2, 4, 1, 2, 2, 2, 3, 1, 2, 4, 3, 3, 4, 0, 0, 1, 3, 0, 3, 4, 0,\n",
            "        0, 1, 2, 2, 1, 1, 4, 3, 2, 3, 3, 3, 2, 4, 4, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En8y1LsOXU9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Embedder(nn.Module):\n",
        "  def __init__(self, text_embedding_vectors, dropout_rate):\n",
        "    super(Embedder, self).__init__()\n",
        "    #tokenの数と、分散表現の次元数\n",
        "    self.embeddings = nn.Embedding.from_pretrained(\n",
        "        embeddings=text_embedding_vectors, freeze=True)\n",
        "    self.dropout = nn.Dropout(dropout_rate)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.embeddings(x).permute(0, 2, 1) #[batch, d_model, length]\n",
        "    x = self.dropout(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "class CNN_Layer(nn.Module):\n",
        "  def __init__(self, d_model, num_filters, filter_sizes, dropout_rate):\n",
        "    super().__init__()\n",
        "    self.convs = nn.ModuleList([nn.Conv1d(d_model, nf, fs) for nf, fs in zip(num_filters, filter_sizes)])\n",
        "    self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = [F.relu(conv(x).permute(0, 2, 1).max(1)[0]) for conv in self.convs]\n",
        "    return x\n",
        "\n",
        "  \n",
        "class ClassificationHead(nn.Module):\n",
        "  def __init__(self, num_unit, output_dim, dropout_rate):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(num_unit*3, output_dim)\n",
        "    self.dropout = nn.Dropout(dropout_rate)\n",
        "    nn.init.normal_(self.linear.weight, std=0.02)\n",
        "    nn.init.normal_(self.linear.bias, 0)\n",
        "\n",
        "  def forward(self, x):\n",
        "    print(x[0].shape)\n",
        "    print(x[1].shape)\n",
        "    print(x[2].shape)\n",
        "    print(torch.cat(x, 1).shape)\n",
        "    # torch.cat(x, 1).shape -> [batch, sum(filter_sizes)]\n",
        "    x = self.linear(torch.cat(x, 1)) # [batch, output_dim]\n",
        "    output = self.dropout(x)\n",
        "    return output\n",
        "\n",
        "class CNN_Classification(nn.Module):\n",
        "  def __init__(self, text_embedding_vectors, d_model, num_filters, filter_sizes, num_unit, droutput_dim, dropout_rate):\n",
        "    super().__init__()\n",
        "    self.net1 = Embedder(text_embedding_vectors, dropout_rate)\n",
        "    self.net2 = CNN_Layer(d_model, num_filters, filter_sizes, dropout_rate)\n",
        "    self.net3 = ClassificationHead(num_unit, output_dim, dropout_rate)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x1 = self.net1(x) # [batch_size, ntoken, d_model]\n",
        "    x2 = self.net2(x1) \n",
        "    out = self.net3(x2) \n",
        "    return out"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0ZnvkXB3QJi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "2e355bbb-1e9b-4889-c0be-45973a8f90e3"
      },
      "source": [
        "#テスト\n",
        "batch = next(iter(train_dl))\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')\n",
        "\n",
        "# モデル構築\n",
        "net = CNN_Classification(TEXT.vocab.vectors, d_model, num_filters, filter_sizes, \n",
        "                         num_unit, output_dim, dropout_rate) \n",
        "#hidden = net.init_hidden(device)\n",
        "\n",
        "# 入出力\n",
        "x = batch.Text[0]\n",
        "x1 = net(x)\n",
        "\n",
        "print(\"入力のテンソルサイズ：\", x.shape)\n",
        "print(\"出力のテンソルサイズ：\", x1.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 100])\n",
            "torch.Size([64, 300])\n",
            "入力のテンソルサイズ： torch.Size([64, 37])\n",
            "出力のテンソルサイズ： torch.Size([64, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YogZG6jJ3o98",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}