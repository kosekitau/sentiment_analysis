{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CBET_TransformerEncoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHMO5jr3nap4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cd2554c8-ef2d-4e80-b268-57879262c0a9"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "#gpuの確認\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHaizegOoOBj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8ab3305d-bb6c-450c-e162-c97aca6548b9"
      },
      "source": [
        "#学習済みの分散表現をロードする\n",
        "from torchtext.vocab import Vectors\n",
        "\n",
        "english_fasttext_vectors = Vectors(name='drive/My Drive/wiki-news-300d-1M.vec')\n",
        "\n",
        "print(english_fasttext_vectors.dim)\n",
        "print(len(english_fasttext_vectors.itos))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/999994 [00:00<?, ?it/s]Skipping token b'999994' with 1-dimensional vector [b'300']; likely a header\n",
            "100%|█████████▉| 999700/999994 [01:32<00:00, 10088.94it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "300\n",
            "999994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3BGm09RoPgf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "45d037e9-a984-4c0c-88e8-be8dfb6f7341"
      },
      "source": [
        "import string\n",
        "import re\n",
        "\n",
        "# 以下の記号はスペースに置き換えます（カンマ、ピリオドを除く）。\n",
        "# punctuationとは日本語で句点という意味です\n",
        "print(\"区切り文字：\", string.punctuation)\n",
        "# !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
        "\n",
        "# 前処理\n",
        "\n",
        "\n",
        "def preprocessing_text(text):\n",
        "    # 改行コードを消去\n",
        "    text = re.sub('<br />', '', text)\n",
        "\n",
        "    # カンマ、ピリオド以外の記号をスペースに置換\n",
        "    for p in string.punctuation:\n",
        "        if (p == \".\") or (p == \",\"):\n",
        "            continue\n",
        "        else:\n",
        "            text = text.replace(p, \" \")\n",
        "\n",
        "    # ピリオドなどの前後にはスペースを入れておく\n",
        "    text = text.replace(\".\", \" . \")\n",
        "    text = text.replace(\",\", \" , \")\n",
        "    return text\n",
        "\n",
        "# 分かち書き（今回はデータが英語で、簡易的にスペースで区切る）\n",
        "\n",
        "\n",
        "def tokenizer_punctuation(text):\n",
        "    return text.strip().split()\n",
        "\n",
        "\n",
        "# 前処理と分かち書きをまとめた関数を定義\n",
        "def tokenizer_with_preprocessing(text):\n",
        "    text = preprocessing_text(text)\n",
        "    ret = tokenizer_punctuation(text)\n",
        "    return ret\n",
        "\n",
        "\n",
        "# 動作を確認します\n",
        "print(tokenizer_with_preprocessing('I like cats+'))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "区切り文字： !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "['I', 'like', 'cats']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2JI-Lk3o2ig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchtext\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "#テキストに処理を行うFieldを定義\n",
        "#fix_lengthはtokenの数\n",
        "TEXT = torchtext.data.Field(sequential=True, use_vocab=True, tokenize=tokenizer_with_preprocessing,\n",
        "                            lower=True, include_lengths=True, batch_first=True, fix_length=37)\n",
        "\n",
        "LABEL = torchtext.data.Field(sequential=False, use_vocab=False)\n",
        "\n",
        "#pandasでcsvを保存するときに、labelをintでキャストしておかないとエラーでるから注意\n",
        "train_ds, val_ds, test_ds = torchtext.data.TabularDataset.splits(\n",
        "    path='drive/My Drive/dataset/CBET/ekman', train='train.csv', validation='val.csv', \n",
        "    test='test.csv', format='csv', fields=[('Text', TEXT), ('Label', LABEL)])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZqJV6xEo6su",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d6d34fb-b14f-4223-8bb1-d39d5e15f51b"
      },
      "source": [
        "#ボキャブラリを作成する\n",
        "TEXT.build_vocab(train_ds, vectors=english_fasttext_vectors)\n",
        "\n",
        "print(len(TEXT.vocab.stoi))\n",
        "\n",
        "batch_size = 64\n",
        "d_model = 300\n",
        "hidden_size = 512\n",
        "output_dim = 5\n",
        "dropout_rate = 0.5"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "51709\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSWHc1Tuo-5E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b1830ece-0880-4574-bb7a-7f16c257e321"
      },
      "source": [
        "#データローダを作成\n",
        "train_dl = torchtext.data.Iterator(train_ds, batch_size=batch_size, train=True)\n",
        "val_dl = torchtext.data.Iterator(val_ds, batch_size=batch_size, train=False, sort=False)\n",
        "test_dl = torchtext.data.Iterator(test_ds, batch_size=batch_size, train=False, sort=False)\n",
        "\n",
        "#テスト\n",
        "batch = next(iter(val_dl))\n",
        "print(len(batch.Text[0][0]))\n",
        "print(batch.Label)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37\n",
            "tensor([4, 0, 2, 0, 2, 4, 4, 3, 1, 4, 2, 2, 1, 2, 2, 2, 1, 2, 3, 3, 0, 3, 4, 1,\n",
            "        1, 3, 0, 2, 4, 1, 2, 2, 2, 3, 1, 2, 4, 3, 3, 4, 0, 0, 1, 3, 0, 3, 4, 0,\n",
            "        0, 1, 2, 2, 1, 1, 4, 3, 2, 3, 3, 3, 2, 4, 4, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RngJvqDTpDKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#モデルの定義\n",
        "class Embedder(nn.Module):\n",
        "  def __init__(self, text_embedding_vecotrs):\n",
        "    super(Embedder, self).__init__()\n",
        "    self.embeddings = nn.Embedding.from_pretrained(\n",
        "        embeddings=text_embedding_vecotrs, freeze=True)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.embeddings(x)\n",
        "    return x\n",
        "\n",
        "class PositionalEncoder(nn.Module):\n",
        "  def __init__(self, d_model, max_seq_len=200, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.dropout = nn.Dropout(dropout_rate)\n",
        "    # create constant 'pe' matrix with values dependant on \n",
        "    # pos and i\n",
        "    pe = torch.zeros(max_seq_len, d_model)\n",
        "    for pos in range(max_seq_len):\n",
        "        for i in range(0, d_model, 2):\n",
        "            pe[pos, i] = \\\n",
        "            math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
        "            pe[pos, i + 1] = \\\n",
        "            math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
        "    pe = pe.unsqueeze(0)\n",
        "    self.register_buffer('pe', pe)\n",
        " \n",
        "    \n",
        "  def forward(self, x):\n",
        "    # make embeddings relatively larger\n",
        "    x = x * math.sqrt(self.d_model)\n",
        "    #add constant to embedding\n",
        "    seq_len = x.size(1)\n",
        "    pe = Variable(self.pe[:,:seq_len], requires_grad=False)\n",
        "    if x.is_cuda:\n",
        "      pe.cuda()\n",
        "    x = x + pe\n",
        "    return self.dropout(x)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8fdqXwDQnfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def attention(q, k, v, d_k, mask=None, dropout=None):\n",
        "\n",
        "  #queryとkeyの関連度をだす\n",
        "  scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k) #[batch, heads, length, length]\n",
        "  #maskをかける\n",
        "  if mask is not None:\n",
        "    mask = mask.unsqueeze(1)\n",
        "    scores = scores.masked_fill(mask==0, -1e9)\n",
        "\n",
        "  #AttentionWeight\n",
        "  scores = F.softmax(scores, dim=-1)\n",
        "  attention_weight = scores\n",
        "\n",
        "  if dropout is not None:\n",
        "    scores = dropout(scores)\n",
        "  print(scores.shape)\n",
        "  print(v.shape)\n",
        "  #valueを取り出す\n",
        "  output = torch.matmul(scores, v) #[batch, heads, length, d_model]\n",
        "  return output, attention_weight\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, heads, d_model, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.d_model = d_model\n",
        "    self.d_k = d_model // heads\n",
        "    self.h = heads\n",
        "    self.q_linear = nn.Linear(d_model, d_model)\n",
        "    self.k_linear = nn.Linear(d_model, d_model)\n",
        "    self.v_linear = nn.Linear(d_model, d_model)\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout_rate)\n",
        "    self.out = nn.Linear(d_model, d_model)\n",
        "\n",
        "  def forward(self, q, k, v, mask=None):\n",
        "    bs = q.size(0)\n",
        "\n",
        "    q = self.q_linear(q).view(bs, -1, self.h, self.d_k) #[batch_size, length, heads, d_k]\n",
        "    k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n",
        "    v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n",
        "\n",
        "    q = q.transpose(1, 2)\n",
        "    k = k.transpose(1, 2)\n",
        "    v = v.transpose(1, 2)\n",
        "\n",
        "    #\n",
        "    scores, attention_weight = attention(q, k, v, self.d_k, mask, self.dropout)\n",
        "    concat = scores.transpose(1, 2).contiguous().view(bs, -1, self.d_model)\n",
        "    output = self.out(concat)\n",
        "    return output, attention_weight\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, d_model, d_ff=2048, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.linear_1 = nn.Linear(d_model, d_ff)\n",
        "    self.dropout = nn.Dropout(dropout_rate)\n",
        "    self.linear_2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.dropout(F.relu(self.linear_1(x)))\n",
        "    x = self.linear_2(x)\n",
        "    return x"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtvKefbSaoJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "  def __init__(self, d_model, heads, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    #LayerNormalizetion\n",
        "    self.norm_1 = nn.LayerNorm(d_model)\n",
        "    self.norm_2 = nn.LayerNorm(d_model)\n",
        "\n",
        "    self.attn = MultiHeadAttention(heads, d_model, dropout_rate=dropout_rate)\n",
        "    self.ff = FeedForward(d_model, dropout_rate=dropout_rate)\n",
        "\n",
        "    self.dropout_1 = nn.Dropout(dropout_rate)\n",
        "    self.dropout_2 = nn.Dropout(dropout_rate)\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    x2 = self.norm_1(x)\n",
        "    output, attention_weight = self.attn(x2, x2, x2, mask)\n",
        "    x = x+self.dropout_1(output)\n",
        "    x2 = self.norm_2(x)\n",
        "    x = x+self.dropout_2(self.ff(x2))\n",
        "\n",
        "    return x, attention_weight"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBpWj1BofKT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "\n",
        "def get_clones(module, N):\n",
        "  return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, text_embedding_vecotrs, N, heads, dropout):\n",
        "    super().__init__()\n",
        "    self.N = N\n",
        "    self.embed = Embedder(text_embedding_vecotrs)\n",
        "    self.pe = PositionalEncoder(d_model, dropout_rate=dropout)\n",
        "    self.layers = get_clones(EncoderLayer(d_model, heads, dropout), N)\n",
        "    self.norm = nn.LayerNorm(d_model)\n",
        "  def forward(self, src, mask):\n",
        "    x = self.embed(src)\n",
        "    x = self.pe(x)\n",
        "    for i in range(self.N):\n",
        "      x, attention_weight = self.layers[i](x, mask)\n",
        "    return self.norm(x), attention_weight"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cpjQa6PgHD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TranformerEncoderClassification(nn.Module):\n",
        "  def __init__(self, text_embedding_vecotrs, d_model, N, heads, output_dim=5, dropout_rate=0.1):\n",
        "    super().__init__()\n",
        "    self.encoder = Encoder(text_embedding_vecotrs, N, heads, dropout_rate)\n",
        "    self.out = nn.Linear(d_model, output_dim)\n",
        "    # 重み初期化処理\n",
        "    nn.init.normal_(self.out.weight, std=0.02)\n",
        "    nn.init.normal_(self.out.bias, 0)\n",
        "\n",
        "  def forward(self, src, mask):\n",
        "    x, attention_weight = self.encoder(src, mask)\n",
        "    output = self.out(x[:, 0, :])\n",
        "    return output, attention_weight"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDXndwBakMgZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "bdf0959d-9730-483d-87f1-4717554a72bf"
      },
      "source": [
        "#テスト\n",
        "batch = next(iter(train_dl))\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')\n",
        "\n",
        "# モデル構築\n",
        "net = TranformerEncoderClassification(TEXT.vocab.vectors, d_model, 3, 5)\n",
        "#hidden = net.init_hidden(device)\n",
        "\n",
        "# 入出力\n",
        "x = batch.Text[0]\n",
        "src_mask = (x != TEXT.vocab.stoi['<pad>']).unsqueeze(-2)\n",
        "print(src_mask.shape)\n",
        "x1, attention_weight = net(x, src_mask)\n",
        "\n",
        "print(\"入力のテンソルサイズ：\", x.shape)\n",
        "print(\"出力のテンソルサイズ：\", x1.shape)\n",
        "print(attention_weight.shape)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 37])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([64, 5, 37, 37])\n",
            "torch.Size([64, 5, 37, 60])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([64, 5, 37, 37])\n",
            "torch.Size([64, 5, 37, 60])\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([64, 5, 37, 37])\n",
            "torch.Size([64, 5, 37, 60])\n",
            "入力のテンソルサイズ： torch.Size([64, 37])\n",
            "出力のテンソルサイズ： torch.Size([64, 5])\n",
            "torch.Size([64, 5, 37, 37])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk7YG0MWkh7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 131,
      "outputs": []
    }
  ]
}