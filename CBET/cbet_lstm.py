# -*- coding: utf-8 -*-
"""CBET_LSTM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X24-0N2zNUjpl5_sANAv0SgXMFDLqa9e
"""

import torch
#gpuの確認
print(torch.cuda.is_available())

import torchtext
from torchtext.data.utils import get_tokenizer

toke = get_tokenizer('spacy')
toke('I am N')

import torchtext
from torchtext.data.utils import get_tokenizer

#テキストに処理を行うFieldを定義
#fix_lengthはtokenの数
TEXT = torchtext.data.Field(sequential=True, use_vocab=True, tokenize=get_tokenizer('spacy'),
                            lower=True, include_lengths=True, batch_first=True, fix_length=37)

LABEL = torchtext.data.Field(sequential=False, use_vocab=False)

#pandasでcsvを保存するときに、labelをintでキャストしておかないとエラーでるから注意
train_ds, val_ds, test_ds = torchtext.data.TabularDataset.splits(
    path='drive/My Drive/dataset/CBET/ekman', train='train.csv', validation='val.csv', 
    test='test.csv', format='csv', fields=[('text', TEXT), ('Label', LABEL)])

#ボキャブラリを作成する
TEXT.build_vocab(train_ds)
#TEXT.build_vocab(train_ds, vectors=japanese_word2vec_vectors) #学習ずみの分散表現を使う場合
print(TEXT.vocab.stoi)

#データローダーを作成
train_dl = torchtext.data.Iterator(train_ds, batch_size=64, train=True)
val_dl = torchtext.data.Iterator(val_ds, batch_size=64, train=False, sort=False)
test_dl = torchtext.data.Iterator(test_ds, batch_size=64, train=False, sort=False)

#テスト
batch = next(iter(val_dl))
print(len(batch.text[0][0]))
print(batch.Label)

